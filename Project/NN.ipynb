{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code aus \"Neuronale Netze selbst programmieren,\n",
    "# ein verst√§ndlicher Einstieg mit Python\"\n",
    "# von Tariq Rashid , O'Reilly\n",
    "# license GPLv2\n",
    "\n",
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import os\n",
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "\n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each inpzt, hidden oputput layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "\n",
    "        # link weight matrices, wih and who \n",
    "        # weights inside the arrays aer w_i_j, where link is from node i to node j in the next layer\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # acitivation function is the sigmoid funciton\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "    \n",
    "        pass\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer        \n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)      \n",
    "        \n",
    "        # calculate signals final output layer        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python\n",
    "# relative path to files\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "# For accessing the file in the parent folder of the current folder\n",
    "# small test data for quick calculations\n",
    "#training_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_train_100.csv')\n",
    "#test_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_test_10.csv')\n",
    "# real test data (60'000 training data / 10'000 test data)\n",
    "training_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_train.csv')\n",
    "test_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_test.csv') \n",
    "test_data_png = os.path.join(fileDir, '../../trainingdata/testdata_mnist/2828_my_own_?.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist training csv file into a list\n",
    "training_data_file = open(training_data_path, 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale input to range 0.01 to 1.00\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist test csv file into a list\n",
    "test_data_file = open(test_data_path, 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#get the first test record\n",
    "all_values = test_data_list[1].split(',')\n",
    "# print the label\n",
    "print(all_values[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26643feeb50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.65473837e-02],\n",
       "       [5.80011380e-03],\n",
       "       [9.97442390e-01],\n",
       "       [1.90289774e-02],\n",
       "       [9.81732523e-04],\n",
       "       [1.75999931e-03],\n",
       "       [3.30384588e-03],\n",
       "       [6.92703868e-04],\n",
       "       [6.56228707e-05],\n",
       "       [1.88403636e-04]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale input to range 0.01 to 1.00\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9409\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score (correct answers/ all answers)\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(image_file_name[-5:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  3\n",
      "0.01\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob(test_data_png):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.26119714e-03]\n",
      " [1.88758653e-02]\n",
      " [7.92301475e-03]\n",
      " [9.70859268e-01]\n",
      " [2.68825063e-03]\n",
      " [1.20350202e-02]\n",
      " [2.31435804e-03]\n",
      " [2.20656573e-02]\n",
      " [5.88354372e-04]\n",
      " [8.68720067e-04]]\n",
      "network says  3\n",
      "match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 0\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
