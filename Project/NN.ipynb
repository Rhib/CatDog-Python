{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code aus \"Neuronale Netze selbst programmieren,\n",
    "# ein verst√§ndlicher Einstieg mit Python\"\n",
    "# von Tariq Rashid , O'Reilly\n",
    "# license GPLv2\n",
    "\n",
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import os\n",
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "\n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each inpzt, hidden oputput layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "\n",
    "        # link weight matrices, wih and who \n",
    "        # weights inside the arrays aer w_i_j, where link is from node i to node j in the next layer\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # acitivation function is the sigmoid funciton\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "\n",
    "        pass\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer        \n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)      \n",
    "        \n",
    "        # calculate signals final output layer        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "\n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.6\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python\n",
    "# relative path to files\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "# For accessing the file in the parent folder of the current folder\n",
    "# small test data for quick calculations\n",
    "#training_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_train_100.csv')\n",
    "#test_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_test_10.csv')\n",
    "# real test data (60'000 training data / 10'000 test data)\n",
    "training_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_train.csv')\n",
    "test_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_test.csv') \n",
    "test_data_png = os.path.join(fileDir, '../../trainingdata/testdata_mnist/2828_my_own_?.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist training csv file into a list\n",
    "training_data_file = open(training_data_path, 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale input to range 0.01 to 1.00\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist test csv file into a list\n",
    "test_data_file = open(test_data_path, 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#get the first test record\n",
    "all_values = test_data_list[1].split(',')\n",
    "# print the label\n",
    "print(all_values[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dbab86d430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.82166815e-02],\n",
       "       [1.15578944e-02],\n",
       "       [9.96933430e-01],\n",
       "       [1.92129588e-01],\n",
       "       [5.61750756e-04],\n",
       "       [4.23666240e-04],\n",
       "       [4.58480392e-04],\n",
       "       [7.28404772e-06],\n",
       "       [2.85995134e-05],\n",
       "       [1.96418182e-05]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale input to range 0.01 to 1.00\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9158\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score (correct answers/ all answers)\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  C:\\Users\\schmi\\Documents\\CatDog-Python\\CatDog-Python\\Project\\../../trainingdata/testdata_mnist\\2828_my_own_3.png\n",
      "0.01\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob(test_data_png):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.27913576e-03]\n",
      " [7.71597183e-02]\n",
      " [3.50864191e-03]\n",
      " [9.83318962e-01]\n",
      " [5.32977511e-04]\n",
      " [7.01717513e-03]\n",
      " [2.21638716e-03]\n",
      " [7.39913305e-04]\n",
      " [4.40337524e-04]\n",
      " [8.92518339e-03]]\n",
      "network says  3\n",
      "match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 0\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dbbc2d3880>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUKUlEQVR4nO3dX4xc5XkG8OfBgP+s8fj/er0xNljGwgIKaGUqUVVUUSPCjclFonAREQnVEQpSIuWiiF6ES1Q1iXKBIjkFxalSokgJggvUBqFIiJuIBYxt6ha76w0Yr3cNttcGGxvbby92qBaz532GObMzI77nJ1m7O++eOd+cOa9ndt7zfh8jAmb25XdVrwdgZt3hZDcrhJPdrBBOdrNCONnNCnF1N3fWaDRicHBwXu5bVRVU/Kqr8v/3su1J1tq32l7FL1++nMbr3Hdddao9dceWba+OWd3nVKnz2LJtjx07hunp6Tl/oVayk7wXwM8BLADwrxHxRPb7g4ODePLJJyvjdU7aTz75JI1funQpjS9ZsiSNnz9/vjJ29dX5Yaz7H426/2xs6nFfc801aVydlGrs2dgUNTa17yx+4cKFdFt1zD/++ONa22fHVR3z7Lg8/PDDlbG238aTXADgSQBfB7ANwAMkt7V7f2Y2v+r8zb4dwKGIGIuICwB+C2BHZ4ZlZp1WJ9mHAbw76+cjzds+g+ROkqMkR6enp2vszszqqJPsc/1h8bk/TiNiV0SMRMRIo9GosTszq6NOsh8BsGHWz18BcLTecMxsvtRJ9lcBbCF5A8lrAXwbwPOdGZaZdVrbpbeIuEjyEQD/iZnS29MR8ZbaLisFXbx4Md02K6Wo0pkqtdSpe9YtranyWJ0yUd2y4Hw+NnXfCxcuTOPK2bNnK2PqfMm2bYU6LgsWLKiMqbJeVqLOYrXq7BHxAoAX6tyHmXWHL5c1K4ST3awQTnazQjjZzQrhZDcrhJPdrBBd7WePiLQVtU5bYN1Wzjq17Kxm2grVBqpqttn1Cepxq7Gr6w/qXL+g9q3q7Oq6jIGBgcqYaolW56KiriE4d+5cZaxOu3XGr+xmhXCymxXCyW5WCCe7WSGc7GaFcLKbFaKrpTeSuPbaayvjqoyzdOnSypgqw9Rtp/zwww/bvu/sMQO6zFOn9Hbq1Kl027pTIp88eTKNZyXRTZs2pdvWaXkG8ue0ztThQL1ZcwFg8eLFtbZvh1/ZzQrhZDcrhJPdrBBOdrNCONnNCuFkNyuEk92sEF1vcc2mulXtmNkUu6ruqeqaqu6abZ+1KwK6hq9Wr1XtmNn1CWpa4r1796Zx1Tqs7j+rpb/xxhvpttl1FQAwPPy51cY+Y82aNZUx1bqravzz/Zxm1HNSxa/sZoVwspsVwsluVggnu1khnOxmhXCymxXCyW5WiK7W2YG8fqmmFs7q8Kr/uO6Uytn9NxqNdNs6y0EDuq6ajX1iYiLd9uDBg2l8bGwsja9fvz6NZ8d9xYoV6baqF18d12zfqs6dTUMN6DkKrrvuujR+5syZtmJq39kxqZXsJMcBnAFwCcDFiBipc39mNn868cr+dxHxfgfux8zmkf9mNytE3WQPAH8k+RrJnXP9AsmdJEdJjk5PT9fcnZm1q+7b+Lsj4ijJtQBeJPnfEfHy7F+IiF0AdgHAli1b6s1uaGZtq/XKHhFHm1+nADwLYHsnBmVmndd2spMcIHndp98D+BqA/Z0amJl1Vp238YMAnm3W9a4G8O8R8R/ZBiTT2qfqjc5qiKq/WFH9x1mdve6c9KqXfnx8PI0fPny4Mvbuu++m22bz4QPA2rVr07iSfU5z/PjxdFt13E6fPp3Gs/n4Fy1alG6r4qrXftmyZWk8O2fqrBMwL3X2iBgD8Fftbm9m3eXSm1khnOxmhXCymxXCyW5WCCe7WSG6PpV0nRbXjJpKWpUz1PZZWVCVadR9q+mcT5w40Xb8wIED6bZnz55N4+qxLVmyJI1n+1ctrHfddVcaV+fLRx99VBlT01CrFlVVblXLcGdTk2fjBvIycVrSS+/VzL40nOxmhXCymxXCyW5WCCe7WSGc7GaFcLKbFaLrU0ln9W5VN83qi6pFVS3Bmy17rO7/5MmT6bZqyuMbbrghjU9NTaXxrA1VtYlOTk6mcdWGunLlyjT+3nvvVcauv/76WvtWjy1bLjpbzhnQdfT33683x2o2dnUue8lmM0s52c0K4WQ3K4ST3awQTnazQjjZzQrhZDcrRFfr7CTTOruqbWa1ctV3fe7cOTm2TLZMrlq+Vy0PrGq2mzdvTuPZNQJDQ0Pptuq4bNmyJY2renW2/LCa5jqr0QP6uB85cqQypvrN61zzAejrNgYHBytjamzqfKriV3azQjjZzQrhZDcrhJPdrBBOdrNCONnNCuFkNytEX80br2S1T1V7VL3Pqmar5vLONBqNNJ7NIQ4gXeYaAMbGxipjaung7du3p3G1NLHaPuv1f+WVV9Jt1bmi+uGXL19eGVN1dHU+KGop7FWrVlXG6qyfkJGv7CSfJjlFcv+s21aSfJHkwebXFfMyOjPrmFbexv8KwL1X3PYogJciYguAl5o/m1kfk8keES8DuHJ9oR0Adje/3w3g/s4Oy8w6rd0P6AYjYgIAml8rJ0EjuZPkKMnR6enpNndnZnXN+6fxEbErIkYiYkR9UGVm86fdZJ8kOQQAza/59Kdm1nPtJvvzAB5sfv8ggOc6Mxwzmy+yzk7yGQD3AFhN8giAHwN4AsDvSD4E4B0A32xlZyTTvnNVV816iFU/+8DAQBo/ffp0Gs8+b1D9x6rWreaFV/OEZ3VZ1Y+u1le/44470viNN96YxrN17dXzreYYyOZGAPJ5AlasyKvFat8nTlz5mfVnrVu3Lo1nj131yqt5H6rIZI+IBypCX21rj2bWE75c1qwQTnazQjjZzQrhZDcrhJPdrBBdb3HNSjGqlTOjSiWKaivMxr1169Z022w65Vbip06dSuMbN25sKwYAt912WxpXJaQ6Uy7feeed6baHDh1q+76BvE1VtUQfO3YsjauWZ3UuDw8PV8bqlN6ymF/ZzQrhZDcrhJPdrBBOdrNCONnNCuFkNyuEk92sEF1fsjmrP6qWxaz+qJYeVtTUv9m41bbZVM8A8M4776Txbdu2pfH169dXxjZt2pRuq+roqn1Xtd9mcVWLXr16dRpXy0VnNefDhw+n26qWZ1VnV9dOHD9+vDKmphbP8iS73sSv7GaFcLKbFcLJblYIJ7tZIZzsZoVwspsVwsluVoiu97NnfcSq7prVF1W9V9Xhs2mHAeD8+fOVsbfffjvd9uzZs2lcXV+g4lktPOubBvRxU/VkVYfPxl53ObCJiYk0nj3n6nxQ8yOoczU7XwDgwoULlTFVZ8+moXY/u5k52c1K4WQ3K4ST3awQTnazQjjZzQrhZDcrRFfr7IqqJ2f1xTrzlwO6LprVL1UdXdWT1b737duXxm+99dbKWN3jopa6Vs/ZyZMnK2PZXPyAvgYgq1UDwPj4eGUsm1Me0EuAr1q1Ko2rpbDVcc1kz1mtOjvJp0lOkdw/67bHSb5Hck/z331fdMBm1l2tvI3/FYB757j9ZxFxe/PfC50dlpl1mkz2iHgZwIkujMXM5lGdD+geIbm3+TZ/RdUvkdxJcpTkaN1roc2sfe0m+y8AbAZwO4AJAD+p+sWI2BURIxEx0mg02tydmdXVVrJHxGREXIqIywB+CWB7Z4dlZp3WVrKTHJr14zcA7K/6XTPrD7LOTvIZAPcAWE3yCIAfA7iH5O0AAsA4gO+1usOs7pvV0YG8d1rVbBW1BnpW081qyYCus69duzaNq5pvVqdX65CrOry6hkCNLavDqzq5ek6zmjKQ9+KrfS9cuDCNqzq9qsNn/fBq35ns+ZTJHhEPzHHzU22Pxsx6wpfLmhXCyW5WCCe7WSGc7GaFcLKbFaKvlmxWZaKsNKem/lVTB6upgT/44IO29z04OJjG60zHDORlQ9XCqkpI6rGp5aqzpYn3788vz1D3PTk5mcZXrKi8iluW7VT5Sz2ny5YtS+N1zuVs2+z59iu7WSGc7GaFcLKbFcLJblYIJ7tZIZzsZoVwspsVoq+mklY133an0AV07XL58uVpPFvSWU15rGrdJ07kU/yp1t+bbrqpMqauL1AtrmrJ5jfffDONZ+2/apnso0ePpnFl8+bNlTHVuqvORVWHV+dEdj6qc1U9Z1X8ym5WCCe7WSGc7GaFcLKbFcLJblYIJ7tZIZzsZoXoap09ItKeddW3nVF1UdUrr2q+Wa1bbauuAVDTGh8+fDiNZ33fY2Nj6bYrV65M46rOrq4ByHrOVT/60qVL03jWrw7kyyavX78+3VZN/60e9+rVq9N49pyrOnq2ba0lm83sy8HJblYIJ7tZIZzsZoVwspsVwsluVggnu1khut7PntUBVd93Nre76h+uKxubqvGrvmzVv6zmVx8dHa2MDQ0NpdvecsstaVzNj66uEVi8eHFlbGBgIN1269ataVzN9Z/Vq9Vzpqh54bMav9q/Wqo6u+/sWhX5yk5yA8k/kTxA8i2SP2jevpLkiyQPNr/mVziYWU+18jb+IoAfRcTNAP4awPdJbgPwKICXImILgJeaP5tZn5LJHhETEfF68/szAA4AGAawA8Du5q/tBnD/PI3RzDrgC31AR3ITgDsA/BnAYERMADP/IQBYW7HNTpKjJEfV9cZmNn9aTnaSSwH8HsAPI+J0q9tFxK6IGImIkUaj0c4YzawDWkp2ktdgJtF/ExF/aN48SXKoGR8CMDU/QzSzTpClN87UhZ4CcCAifjor9DyABwE80fz6XAv3VavkkJUV1LLHyqpVq9J4VsZR0wqr1l3VAnvzzTen8ay0t2jRonTb8+fPp/FsOWgA2LBhQxpfs2ZNZSwrywHAxo0b07gqb2XHXT0uVbJUZT81VXVGnS/tlplbyZC7AXwHwD6Se5q3PYaZJP8dyYcAvAPgm22NwMy6QiZ7RLwCoOqqj692djhmNl98uaxZIZzsZoVwspsVwsluVggnu1kh+moqaVUrrzP9rmpJVFNNZ9Maq1ZNVUfPpoIGdKtnNjZVZ1e1bjUlsjquw8PDlTF1fYKqs6vlqLNpsFUdXT1naippdc1Idv918iBrxfYru1khnOxmhXCymxXCyW5WCCe7WSGc7GaFcLKbFaLrU0lnvbiqvpj1wqseX1WHX7duXRrPaptq6WBVT56ayuf9ULXyrK9b1cHV9N1qymU11XTWi6+uT5jPayPU41Z1cnU+Kdm5Xmd+hFpTSZvZl4OT3awQTnazQjjZzQrhZDcrhJPdrBBOdrNCdL3OrubEzmQ9wKo2eebMmTSe9T4D+Tzhqhat+rLVnPVqbFnNWNWD1TUC6toH1e+eUUtVq55xddyzudvVUtOqzq7ONxXPevHVccnm+nc/u5k52c1K4WQ3K4ST3awQTnazQjjZzQrhZDcrRCvrs28A8GsA6wBcBrArIn5O8nEA/wDgePNXH4uIF8R9pXX2OnN1q/5kRa23nY1bzb2uatWNRiONZ33ZQF5LV3V2VcNXY1f16CyuxjY9PZ3G1RwG2dhVLVvV8NU1AHWvEchk50N2TFu5qOYigB9FxOskrwPwGskXm7GfRcS/fJGBmllvtLI++wSAieb3Z0geAFC9zIeZ9aUv9Dc7yU0A7gDw5+ZNj5DcS/JpknNed0lyJ8lRkqPqbZmZzZ+Wk53kUgC/B/DDiDgN4BcANgO4HTOv/D+Za7uI2BURIxExov42NbP501Kyk7wGM4n+m4j4AwBExGREXIqIywB+CWD7/A3TzOqSyc6Zjy2fAnAgIn466/bZy2B+A8D+zg/PzDqllU/j7wbwHQD7SO5p3vYYgAdI3g4gAIwD+J66o4hIS2Sq/JWVS1TpTcWz6ZiBfNpiNaWxKk+pMoyKZ0s+q8etyleqNKemuc5aPdW+1ZLM6nzJSrlq33VasVuRlebU48pad7Pnu5VP418BMFeWpTV1M+svvoLOrBBOdrNCONnNCuFkNyuEk92sEE52s0J0dSppkmnNWLUFZjXEuksP1215rKNuvTltaxQtqqqeXLd1OKMet6JaorOxq23V+aCOi2rfzY57nXM5G7df2c0K4WQ3K4ST3awQTnazQjjZzQrhZDcrhJPdrBBU9caO7ow8DuAvs25aDeD9rg3gi+nXsfXruACPrV2dHNvGiFgzV6Cryf65nZOjETHSswEk+nVs/TouwGNrV7fG5rfxZoVwspsVotfJvqvH+8/069j6dVyAx9auroytp3+zm1n39PqV3cy6xMluVoieJDvJe0n+D8lDJB/txRiqkBwnuY/kHpKjPR7L0ySnSO6fddtKki+SPNj8Oucaez0a2+Mk32seuz0k7+vR2DaQ/BPJAyTfIvmD5u09PXbJuLpy3Lr+NzvJBQDeBvD3AI4AeBXAAxHxX10dSAWS4wBGIqLnF2CQ/FsAHwL4dUTc0rztnwGciIgnmv9RroiIf+yTsT0O4MNeL+PdXK1oaPYy4wDuB/Bd9PDYJeP6Frpw3Hrxyr4dwKGIGIuICwB+C2BHD8bR9yLiZQAnrrh5B4Ddze93Y+Zk6bqKsfWFiJiIiNeb358B8Oky4z09dsm4uqIXyT4M4N1ZPx9Bf633HgD+SPI1kjt7PZg5DEbEBDBz8gBY2+PxXEku491NVywz3jfHrp3lz+vqRbLPNUlWP9X/7o6IOwF8HcD3m29XrTUtLePdLXMsM94X2l3+vK5eJPsRABtm/fwVAEd7MI45RcTR5tcpAM+i/5ainvx0Bd3m16kej+f/9dMy3nMtM44+OHa9XP68F8n+KoAtJG8geS2AbwN4vgfj+BySA80PTkByAMDX0H9LUT8P4MHm9w8CeK6HY/mMflnGu2qZcfT42PV8+fOI6Po/APdh5hP5/wXwT70YQ8W4bgTwZvPfW70eG4BnMPO27hPMvCN6CMAqAC8BONj8urKPxvZvAPYB2IuZxBrq0dj+BjN/Gu4FsKf5775eH7tkXF05br5c1qwQvoLOrBBOdrNCONnNCuFkNyuEk92sEE52s0I42c0K8X/LuNO3XTa6uAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
