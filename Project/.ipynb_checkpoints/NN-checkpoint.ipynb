{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code aus \"Neuronale Netze selbst programmieren,\n",
    "# ein verst√§ndlicher Einstieg mit Python\"\n",
    "# von Tariq Rashid , O'Reilly\n",
    "# license GPLv2\n",
    "\n",
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import os\n",
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "\n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each inpzt, hidden oputput layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "\n",
    "        # link weight matrices, wih and who \n",
    "        # weights inside the arrays aer w_i_j, where link is from node i to node j in the next layer\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # acitivation function is the sigmoid funciton\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "\n",
    "        pass\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer        \n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)      \n",
    "        \n",
    "        # calculate signals final output layer        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "\n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.6\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python\n",
    "# relative path to files\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "# For accessing the file in the parent folder of the current folder\n",
    "# small test data for quick calculations\n",
    "#training_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_train_100.csv')\n",
    "#test_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_test_10.csv')\n",
    "# real test data (60'000 training data / 10'000 test data)\n",
    "training_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_train.csv')\n",
    "test_data_path = os.path.join(fileDir, '../../trainingdata/testdata_mnist/mnist_test.csv') \n",
    "test_data_png = os.path.join(fileDir, '../../trainingdata/testdata_mnist/2828_my_own_?.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist training csv file into a list\n",
    "training_data_file = open(training_data_path, 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale input to range 0.01 to 1.00\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist test csv file into a list\n",
    "test_data_file = open(test_data_path, 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#get the first test record\n",
    "all_values = test_data_list[1].split(',')\n",
    "# print the label\n",
    "print(all_values[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dbab86d430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.82166815e-02],\n",
       "       [1.15578944e-02],\n",
       "       [9.96933430e-01],\n",
       "       [1.92129588e-01],\n",
       "       [5.61750756e-04],\n",
       "       [4.23666240e-04],\n",
       "       [4.58480392e-04],\n",
       "       [7.28404772e-06],\n",
       "       [2.85995134e-05],\n",
       "       [1.96418182e-05]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale input to range 0.01 to 1.00\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9158\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score (correct answers/ all answers)\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  C:\\Users\\schmi\\Documents\\CatDog-Python\\CatDog-Python\\Project\\../../trainingdata/testdata_mnist\\2828_my_own_3.png\n",
      "0.01\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob(test_data_png):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.27913576e-03]\n",
      " [7.71597183e-02]\n",
      " [3.50864191e-03]\n",
      " [9.83318962e-01]\n",
      " [5.32977511e-04]\n",
      " [7.01717513e-03]\n",
      " [2.21638716e-03]\n",
      " [7.39913305e-04]\n",
      " [4.40337524e-04]\n",
      " [8.92518339e-03]]\n",
      "network says  3\n",
      "match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 0\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dbbc3d6cd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 5\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getAllNN\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numberNeuralNetworkList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-dd59e04c4f13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mnumberNeuralNetworkList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreadNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"numberNN: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumberNeuralNetworkList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'numberNeuralNetworkList' is not defined"
     ]
    }
   ],
   "source": [
    "trained_Number_NN_Path = os.path.join(fileDir, 'Project/Trained_NN/Numbers/numberNN*.nn') \n",
    "numberNeuralNetworkList = []\n",
    "print(\"getAllNN\")\n",
    "# for every numberNN file in the folder\n",
    "for trained_NN_Path in glob.glob(trained_Number_NN_Path):\n",
    "    print(\"getAllNN current path: \",trained_NN_Path)\n",
    "    # open the file and save the object \n",
    "    with open(trained_NN_Path, 'rb') as input:\n",
    "        # read the nn\n",
    "        readNN = pickle.load(input)\n",
    "        if not readNN.empty:\n",
    "            # append it to the list of NNs\n",
    "            numberNeuralNetworkList.append(readNN)\n",
    "\n",
    "print(\"numberNN: \",numberNeuralNetworkList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
